{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361838da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from models.vqvae import VQVAE\n",
    "from masked_transformer import *\n",
    "from torch.utils.data import DataLoader\n",
    "from pipeline_utils import MRITokenDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc3c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/mingjie/mri230/vqvae_checkpoints/newloss_reshiddens32_n_embeddings64_embed_dim16.pth'\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "model = VQVAE(\n",
    "    h_dim=128, res_h_dim=32, n_res_layers=2,\n",
    "    n_embeddings=64, embedding_dim=16, beta=0.25\n",
    ")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "data = np.load(\"/home/mingjie/mri230/train_data/train_data.npy\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "data = torch.from_numpy(data[:n]).float().to(device)   # shape (n, 1, 256, 256)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, _, _, tokens = model(data)\n",
    "\n",
    "tokens = tokens.cpu().numpy()\n",
    "print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2bcd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'newloss_reshiddens32_n_embeddings64_embed_dim16.pth'\n",
    "context_slices = 3\n",
    "mask_prob = 0.25\n",
    "\n",
    "train_token_seq, val_token_seq, test_token_seq = tokenize(checkpoint_name, res_h_dim=32, embedding_dim=16)\n",
    "\n",
    "train_dataset = MRITokenDataset(tokens=train_token_seq, context_slices=context_slices, mask_prob=mask_prob)\n",
    "val_dataset = MRITokenDataset(tokens=val_token_seq, context_slices=context_slices, mask_prob=mask_prob)\n",
    "test_dataset = MRITokenDataset(tokens=test_token_seq, context_slices=context_slices, mask_prob=mask_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a252ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_workers = 4 \n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    ")\n",
    "\n",
    "x, labels = next(iter(train_dataloader))\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train token range: {min(train_token_seq)} to {max(train_token_seq)}\")\n",
    "print(f\"val token range: {min(val_token_seq)} to {max(val_token_seq)}\")\n",
    "print(f\"test token range: {min(test_token_seq)} to {max(test_token_seq)}\")\n",
    "\n",
    "print(f\"train unique tokens used: {len(np.unique(train_token_seq))}\")\n",
    "print(f\"val unique tokens used: {len(np.unique(val_token_seq))}\")\n",
    "print(f\"test unique tokens used: {len(np.unique(test_token_seq))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
